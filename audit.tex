\label{sec:audit}

The E2E feature of \projname enables individual voters to confirm that their votes were included in the
tabulation, and that the encrypted votes were added correctly.
The challenge feature, if used by enough voters, assures that the encryption was honest
and that substantially all the votes are included in the tabulation.
But there might not be many voters who challenge the system; the voters who do are hardly
representative of the voting public; and some problems may go unnoticed.
Moreover, E2E does not allow a voter to confirm that \emph{others'} ballots were
included in the tabulation, only that those ballots that were included were included correctly.

The paper audit trail enables an entirely independent check 
that the votes were included and tabulated accurately, that
the visible trace of voter intent as reflected in the ballot agrees with the encryption, and, importantly, that
the winners reported by the voting system are the winners that a full hand count of the audit trail would
reveal.
The key is to perform a compliance audit to ensure that the audit trail of paper ballots
is adequately intact to determine the outcomes, and then to perform a risk-limiting
audit of the machine interpretation against a manual interpretation of the paper ballots.
For the risk-limiting audit, \projname uses SOBA~\cite{benalohEtal11} with improvements
given by~\cite{lindemanStark12}.

A risk-limiting audit guarantees a large minimum chance of a full hand count of the audit trail if the
reported outcome (i.e., the set of winners) 
disagrees with the outcome that the full hand count would reveal.
The full hand count then sets the record straight, correcting the outcome before it becomes official.
Risk-limiting audits are widely considered best practice for election audits~\cite{bestPractices08,whitePaper12}.

The most efficient risk-limiting audits, ballot-level comparison audits, rely on comparing 
the machine interpretation of individual ballots
(cast vote records or CVRs) 
against a hand interpretation of the same ballots \cite{stark10d,benalohEtal11,lindemanStark12}.
Current federally certified voting systems do not report cast vote records, so they cannot
be audited using the most efficient techniques \cite{lindemanStark12,starkWagner12}.
This necessitates expensive work-arounds.\footnote{% 
    For instance, a {\em transitive audit\/} might require marking the ballots with unique identifiers
    or keeping them in a prescribed order, re-scanning all the ballots to make digital images,
    and processing those images with software that can construct CVRs from the images and
   associate the CVRs with the ballots.
   That software in turn needs to be programmed with the all the ballot definitions in the contest,
    which itself entails a great deal of error-prone handwork.
}
The preamble to conducting a ballot-level comparison audit using currently deployed voting systems
can annihilate the efficiency advantage of ballot-level comparison
audits~\cite{starkWagner12}.

A big advantage of \projname is that it records and stores individual cast vote records in a way that 
{\em can\/} be linked to
the paper ballot each purports to represent, through encrypted identifiers
of the ballot corresponding to each voter's selections, separately for each contest.
This makes ballot-level comparison audits extremely simple and efficient.
It also reduces the vulnerability of the audit to human error, such as accidental changes to the order
of the physical ballots.\footnote{%
   For instance, we have seen groups of ballots dropped on the floor accidentally;
   even though none was lost, restoring them to their original order was impossible.
}

A comparison audit can be thought of as consisting of two parts:
Checking the addition of the data,\footnote{%
   This presupposes that the contest under audit is a plurality, majority, super-majority, or vote-for-$k$
   contest.
   The operation that must be checked to audit an instant-runoff contest is not addition, but the
   same principle applies.
}
and randomly spot-checking the accuracy of the data added, to confirm that they are accurate
enough for their tabulation to give the correct electoral outcome.
The data are the votes as reported by the voting system.
For the audit to be meaningful, the election official must commit to the vote data before the
pot-checking begins.
Moreover, for the public to verify readily that the reported votes sum to the reported contest totals,
it helps to publish the individual reported votes.
However, if these votes were published ballot by ballot, pattern voting could be used to signal voter identity,
opening a communication channel that might enable 
widespread wholesale coercion~\cite{rescorla09,benalohEtal11}.

The SOBA risk-limiting protocol \cite{benalohEtal11} solves both of these problems:
It allows the election official to commit cryptographically and publicly to the vote data; it publishes
the vote data in plain text but ``unbundled'' into separate contests so that pattern voting cannot
be used to signal.
Moreover, the computations that SOBA requires are extremely simple (they are simplified
even further by \cite{lindemanStark12}).
The simplicity increases transparency, because observers can confirm that the calculations
were done correctly with a pencil and paper or a hand calculator.

The encrypted ballot/contest identifiers on the ballot that \projname produces 
allow the electronic cast vote records for each contest to be linked to
the paper they purport to represent.
This simplifies SOBA procedures because it eliminates the need to store ballots in a rigid order.
Moreover, because the voting terminal generates both the electronic vote data and the paper ballot, 
the audit should find very few if any discrepancies between them.

But since voters and election workers will handle the ballots in transit from the voting terminal 
to the scanner to the audit, voters might make marks on their ballots.
Depending on the rules in place for ascertaining voter intent from the ballot,
those marks might be interpreted as expressing voter intent different from the
machine-printed selections, in which case the SOBA audit might find discrepancies.

It could also happen that a ballot enters the ballot box but its serial number is not
picked up, so the electronic vote data ends up in the ``untallied but unspoiled'' group.
This should be detectable by a compliance audit \cite{benalohEtal11,lindemanStark12,starkWagner12} 
as a mismatch between the number of recorded votes and the number of pieces of paper,
providing an opportunity to resolve the problem before the audit begins.

If such cases remain and turn up in the audit sample, SOBA would count them as discrepancies 
and the sample might need to expand, either
until there is strong evidence that the electoral outcomes are correct despite any errors the audit
uncovers, or until there has been a complete hand count.

The random selection of ballots for the SOBA audit should involve public participation in
generating many bits of entropy to seed a high-quality, public, pseudo-random 
number generator (PRNG), which is then used to select a sequence of
ballots to inspect manually~\cite{lindemanStark12}.
(For instance, audit observers might roll 10-sided dice repeatedly to generate a 20-digit number.)
Publishing the PRNG algorithm adds transparency by allowing observers to verify
that the selection of ballots was fair.

%[PBS:  Do we want to go further and talk about how to generate the random sample?  \cite{lindemanStark12}
%spends some time on this, including discussing Rivest's approach that starts with dice rolls for entropy then
%applies SHA-256.]

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "star"
%%% End: 

